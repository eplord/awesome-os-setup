# torch with CUDA support
--extra-index-url https://download.pytorch.org/whl/cu121
torch==2.2.0

# llama-cpp-python with CUDA support
llama-cpp-python@ https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/wheels/llama_cpp_python-0.2.19+cu121-cp311-cp311-manylinux_2_31_x86_64.whl

# requirements
-r requirements.txt

# ExLlama
exllama@ https://github.com/jllllll/exllama/releases/download/0.0.18/exllama-0.0.18+cu121-cp311-cp311-linux_x86_64.whl

# ExLlamaV2
exllamav2@ https://github.com/turboderp/exllamav2/releases/download/v0.0.9/exllamav2-0.0.9+cu121-cp311-cp311-linux_x86_64.whl

# Spacy with cuda
spacy[cuda-autodetect]
